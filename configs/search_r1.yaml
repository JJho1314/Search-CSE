
# SE Configuration for Search-R1 (QA Search & Reasoning)
# Task: Answer questions using multi-turn search and reasoning

# 任务类型
task_type: search_r1
metric_higher_is_better: true   # 新增：EM 评估，越大越好
# PerfAgent 使用的 LLM（本地 vLLM server，对应 Search-R1 的 actor 模型）
# 启动方式：
#   python -m vllm.entrypoints.openai.api_server \
#       --model /data/user/rli112/junjie/workspace/LLM_Agent/weight/SearchR1-nq_hotpotqa_train-qwen2.5-3b-em-grpo-v0.3 \
#       --port 8000 --dtype bfloat16 --tensor-parallel-size 1
model:
  name: SearchR1-nq_hotpotqa_train-qwen2.5-7b-it-em-grpo-v0.3
  api_base: http://127.0.0.1:8000/v1
  api_key: "EMPTY"
  max_input_tokens: 30000
  max_output_tokens: 5000
  temperature: 0.7

# 算子模型配置（用于轨迹总结等，可与 PerfAgent 模型相同或用更强的模型）
operator_models:
  name: SearchR1-nq_hotpotqa_train-qwen2.5-7b-it-em-grpo-v0.3
  api_base: http://127.0.0.1:8000/v1
  api_key: "EMPTY"
  max_input_tokens: 30000
  max_output_tokens: 5000
  temperature: 0.7

operator_selection_mode: weighted

local_memory:
  enabled: false

global_memory_bank:
  enabled: false

# 实例配置
instances:
  instances_dir: instances/

output_dir: "trajectories_perf/search_r1_test_{timestamp}"

prompt_config:
  summarizer:
    enable_summary: true
    system_prompt: |
      You are an AI assistant specialized in analyzing search-augmented QA reasoning trajectories.

      The agent's goal is to answer a factual question correctly by searching for relevant information
      and reasoning step by step. The evaluation is binary: 1.0 if the answer matches the ground truth
      (Exact Match), 0.0 otherwise.

      The agent uses:
      - <think>...</think> to reason about the question and search results
      - <search>query</search> to search for information
      - <information>...</information> contains search results returned by the engine
      - <answer>...</answer> to provide the final answer

      Your goal is to summarize the agent's search and reasoning journey: what queries were tried,
      what information was found, how the reasoning evolved, and whether the final answer is correct.

      Return your analysis in JSON format with:
      - "solution_name": A short nickname for the search strategy used (e.g., "direct_search", "multi_hop_v2", "entity_chain")
      - "approach_summary": High-level narrative of the search and reasoning journey
      - "search_queries": List of search queries used and their effectiveness
      - "reasoning_quality": Assessment of the reasoning chain (logical, missed connections, etc.)
      - "answer_quality": Whether the final answer directly addresses the question
      - "key_learnings": Insights about effective search strategies for this type of question

    user_prompt_template: |
      Analyze the following search-augmented QA trajectory. The agent's goal was to answer the question
      correctly using search and reasoning (binary metric: Exact Match).

      Problem description:
      {problem_description}

      Trajectory data (.tra file):
      {trajectory_content}

      Final answer trajectory:
      {solution_content}

      Provide your analysis in the JSON format specified in the system prompt.

  reflection_refine:
    header: |
      IMPORTANT: Your previous attempt gave a WRONG answer. The previous attempt is shown below.
      You MUST NOT repeat the same wrong answer. The answer shown below is INCORRECT.
      Try completely different search queries and reasoning to find the correct answer.
    guidelines: |
      Rules:
      1. The answer in the previous attempt is WRONG — NEVER give that same answer again.
      2. The information that led to that wrong answer may also be wrong — do NOT trust it.
      3. Use DIFFERENT search queries than what was tried before. Search for each entity separately.
      4. Carefully check dates, names, and facts in the search results before concluding.
      5. Put your final answer inside <answer>...</answer> tags.

  crossover:
    header: |
      IMPORTANT: Two previous attempts are shown below. BOTH gave WRONG answers.
      You MUST NOT repeat either wrong answer. Both answers shown below are INCORRECT.
      Use any useful search results from both attempts, but reach a DIFFERENT conclusion.
    guidelines: |
      Rules:
      1. Both answers below are WRONG — NEVER give either of them as your answer.
      2. The information that led to those wrong answers may be incorrect — verify everything.
      3. Look at what useful facts each attempt found, but do NOT trust their conclusions.
      4. Try NEW search queries to find information that both attempts missed.
      5. Carefully check dates, names, and facts before concluding.
      6. Put your final answer inside <answer>...</answer> tags.

max_iterations: 1 # This config defines a single, multi-step iteration.

# 基础配置引用
base_config: "configs/perf_configs/config_search_r1.yaml"

# 策略编排
# 策略编排
strategy:
  iterations:
    # ==========================================================================
    # Initialization: Planner generates K=5 initial solutions
    # ==========================================================================
    - operator: "plan"
      num: 5
      trajectory_labels: ["iter1_sol1", "iter1_sol2", "iter1_sol3", "iter1_sol4", "iter1_sol5"]

    # ==========================================================================
    # Evolution: 10 hard-coded steps of exploration and exploitation
    # Operators will use weighted selection from the entire pool of trajectories.
    # ==========================================================================

    # Step 1: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter1_sol6"

    # Step 2: Crossover
    - operator: "crossover"
      trajectory_label: "iter1_sol7"

    # Step 3: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter1_sol8"

    # Step 4: Crossover
    - operator: "crossover"
      trajectory_label: "iter1_sol9"

    # Step 5: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter1_sol10"

    # Step 6: Crossover
    - operator: "crossover"
      trajectory_label: "iter1_sol11"

    # Step 7: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter1_sol12"

    # Step 8: Crossover
    - operator: "crossover"
      trajectory_label: "iter1_sol13"

    # Step 9: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter1_sol14"

    # Step 10: Crossover
    - operator: "crossover"
      trajectory_label: "iter1_sol15"

    # Iteration 2 
    # ==========================================================================
    # Evolution: 10 hard-coded steps of exploration and exploitation
    # ==========================================================================

    # Step 1: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter2_sol1"

    # Step 2: Crossover
    - operator: "crossover"
      trajectory_label: "iter2_sol2"

    # Step 3: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter2_sol3"

    # Step 4: Crossover
    - operator: "crossover"
      trajectory_label: "iter2_sol4"

    # Step 5: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter2_sol5"

    # Step 6: Crossover
    - operator: "crossover"
      trajectory_label: "iter2_sol6"

    # Step 7: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter2_sol7"

    # Step 8: Crossover
    - operator: "crossover"
      trajectory_label: "iter2_sol8"

    # Step 9: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter2_sol9"

    # Step 10: Crossover
    - operator: "crossover"
      trajectory_label: "iter2_sol10"

    # Iteration 3
    # ==========================================================================
    # Evolution: 10 hard-coded steps of exploration and exploitation
    # ==========================================================================

    # Step 1: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter3_sol1"

    # Step 2: Crossover
    - operator: "crossover"
      trajectory_label: "iter3_sol2"

    # Step 3: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter3_sol3"

    # Step 4: Crossover
    - operator: "crossover"
      trajectory_label: "iter3_sol4"

    # Step 5: Reflection and Refine
    - operator: "reflection_refine"
      trajectory_label: "iter3_sol5"